{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d7fbdb2-9a0b-4ba8-b0cb-172fa7c94eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f76e9cc70d0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import os.path as osp\n",
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datasets.dataset as dataset\n",
    "from datasets.dataset import load_data, CLASS_MAP\n",
    "import models.models as models\n",
    "from utils.data_class import BrainDataset\n",
    "import torchio as tio\n",
    "#from models.models import FujiNet1 #, Vgg16,\n",
    "\n",
    "SEED_VALUE = 2481\n",
    "np.random.seed(SEED_VALUE)\n",
    "torch.manual_seed(SEED_VALUE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a85cdf6-b88c-48c3-86ec-b0364db54de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jun 28 19:35:03 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.47.03    Driver Version: 510.47.03    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA RTX A6000    On   | 00000000:05:00.0 Off |                  Off |\n",
      "| 30%   46C    P2   128W / 300W |  43784MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA RTX A6000    On   | 00000000:06:00.0 Off |                  Off |\n",
      "| 30%   44C    P2   119W / 300W |  41022MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA RTX A6000    On   | 00000000:07:00.0 Off |                  Off |\n",
      "| 30%   50C    P2   136W / 300W |  38430MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA RTX A6000    On   | 00000000:08:00.0 Off |                  Off |\n",
      "| 30%   47C    P2   120W / 300W |  47790MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  NVIDIA RTX A6000    On   | 00000000:0B:00.0 Off |                  Off |\n",
      "| 30%   46C    P2   121W / 300W |  34828MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  NVIDIA RTX A6000    On   | 00000000:0D:00.0 Off |                  Off |\n",
      "| 30%   50C    P2   124W / 300W |  43178MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  NVIDIA RTX A6000    On   | 00000000:0E:00.0 Off |                  Off |\n",
      "| 30%   45C    P2   122W / 300W |  42028MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  NVIDIA RTX A6000    On   | 00000000:0F:00.0 Off |                  Off |\n",
      "| 30%   51C    P2   125W / 300W |  43132MiB / 49140MiB |    100%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A   1553275      C   ...hic-vqa-dev/bin/python3.8    43781MiB |\n",
      "|    1   N/A  N/A    287834      C                                    3309MiB |\n",
      "|    1   N/A  N/A    666779      C                                    3309MiB |\n",
      "|    1   N/A  N/A   1553276      C   ...hic-vqa-dev/bin/python3.8    34387MiB |\n",
      "|    2   N/A  N/A   1553278      C   ...hic-vqa-dev/bin/python3.8    38427MiB |\n",
      "|    3   N/A  N/A   1553279      C   ...hic-vqa-dev/bin/python3.8    47787MiB |\n",
      "|    4   N/A  N/A   1553281      C   ...hic-vqa-dev/bin/python3.8    34825MiB |\n",
      "|    5   N/A  N/A   1553282      C   ...hic-vqa-dev/bin/python3.8    43175MiB |\n",
      "|    6   N/A  N/A   1553284      C   ...hic-vqa-dev/bin/python3.8    42025MiB |\n",
      "|    7   N/A  N/A   1553285      C   ...hic-vqa-dev/bin/python3.8    43129MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b06e20c-bcaa-4ec2-afdb-c941b11ceefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "#この環境変数は最初に宣言しないと有効にならない\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ecf667-1730-4cce-ab58-9045e822b6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|████████▌                                                            | 241/1939 [00:17<02:43, 10.41it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# dataset ADNI2-2, PPMI, OASIS, \u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkinds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mADNI2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mADNI2-2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCN\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munique\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# dataset = load_data(kinds=[\"PPMI\"], classes=[\"Control\"], unique=True)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# dataset = load_data(kinds=[\"OASIS\"], classes=[\"Control\"], unique=True)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mlen\u001b[39m(dataset)\n",
      "File \u001b[0;32m~/brain/datasets/dataset.py:286\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(kinds, classes, size, csv, pids, uids, unique, blacklist, dryrun)\u001b[0m\n\u001b[1;32m    275\u001b[0m     df \u001b[38;5;241m=\u001b[39m load_csv_data([data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m    276\u001b[0m     [\n\u001b[1;32m    277\u001b[0m         data\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    278\u001b[0m             AGE\u001b[38;5;241m=\u001b[39mdf[df\u001b[38;5;241m.\u001b[39mPID \u001b[38;5;241m==\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mAGE\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset\n\u001b[1;32m    284\u001b[0m     ]\n\u001b[0;32m--> 286\u001b[0m [data\u001b[38;5;241m.\u001b[39mupdate(voxel\u001b[38;5;241m=\u001b[39mread_voxel(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m])) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(dataset)\n",
      "File \u001b[0;32m~/brain/datasets/dataset.py:286\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    275\u001b[0m     df \u001b[38;5;241m=\u001b[39m load_csv_data([data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset])\n\u001b[1;32m    276\u001b[0m     [\n\u001b[1;32m    277\u001b[0m         data\u001b[38;5;241m.\u001b[39mupdate(\n\u001b[1;32m    278\u001b[0m             AGE\u001b[38;5;241m=\u001b[39mdf[df\u001b[38;5;241m.\u001b[39mPID \u001b[38;5;241m==\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpid\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mAGE\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m dataset\n\u001b[1;32m    284\u001b[0m     ]\n\u001b[0;32m--> 286\u001b[0m [data\u001b[38;5;241m.\u001b[39mupdate(voxel\u001b[38;5;241m=\u001b[39m\u001b[43mread_voxel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpath\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m tqdm(dataset, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)]\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(dataset)\n",
      "File \u001b[0;32m~/brain/datasets/dataset.py:71\u001b[0m, in \u001b[0;36mread_voxel\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;124;03mpathを受け取ってvoxelを返すだけ\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mArgs\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;124;03m    pklファイルの中身\u001b[39;00m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m rf:\n\u001b[0;32m---> 71\u001b[0m     voxel \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(voxel)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# dataset ADNI2-2, PPMI, OASIS, \n",
    "dataset = load_data(kinds=[\"ADNI2\", \"ADNI2-2\"], classes=[\"CN\", \"AD\"], unique=False)\n",
    "# dataset = load_data(kinds=[\"PPMI\"], classes=[\"Control\"], unique=True)\n",
    "# dataset = load_data(kinds=[\"OASIS\"], classes=[\"Control\"], unique=True)\n",
    "\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236b456b-b69e-46af-a0f1-46f8434f5b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainとtest用の画像を、同じ患者が分かれて入らないように分ける。\n",
    "from sklearn.model_selection import GroupShuffleSplit, train_test_split\n",
    "\n",
    "# train_datadict, val_datadict = train_test_split(dataset, test_size=0.2, shuffle=True, random_state=SEED_VALUE)\n",
    "pids = []\n",
    "for i in range(len(dataset)):\n",
    "    pids.append(dataset[i][\"pid\"])\n",
    "gss = GroupShuffleSplit(test_size=1-0.8, random_state=SEED_VALUE)\n",
    "train_idx, val_idx = list(gss.split(dataset, groups=pids))[0]\n",
    "train_datadict = dataset[train_idx]\n",
    "val_datadict = dataset[val_idx]\n",
    "\n",
    "len(train_datadict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e017b7-2898-438e-b550-d91015c7168c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import torch.multiprocessing as multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c17073-9014-4c3f-98ba-ab49be8a6387",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if multiprocessing.get_start_method() == \"fork\":\n",
    "#    multiprocessing.set_start_method(\"spawn\", force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ad44d9-9c72-4354-bf9d-c39c2ea30406",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tensor_lodaer(path: str, device=device) -> Any:\n",
    " #   return torvhvisionio.read_image(path).to(device=device)\n",
    "  #  torch.nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6fe626-9442-4ee6-9565-f19d91ca692a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TorchIO\n",
    "class ImageTransformio():\n",
    "    def __init__(self):\n",
    "        self.transform = {\n",
    "            \"train\": tio.Compose([\n",
    "                tio.transforms.RandomAffine(scales=(0.9, 1.1), degrees=10, isotropic=True,\n",
    "                                 center=\"image\", default_pad_value=\"mean\", image_interpolation='linear'),\n",
    "                # tio.transforms.RandomNoise(),\n",
    "                # tio.transforms.RandomBiasField(),\n",
    "                # tio.ZNormalization(),\n",
    "                #tio.transforms.RescaleIntensity((0, 1))\n",
    "            ]),\n",
    "            \"val\": tio.Compose([\n",
    "                # tio.ZNormalization(),\n",
    "                # tio.RescaleIntensity((0, 1))  # , in_min_max=(0.1, 255)),\n",
    "            ])\n",
    "        }\n",
    "\n",
    "    def __call__(self, img, phase=\"train\"):\n",
    "        img_t = torch.tensor(img)\n",
    "        return self.transform[phase](img_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10da6261-5719-4f92-bdda-da78665e6447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/val dataset を作成\n",
    "train_dataset = BrainDataset(data_dict=train_datadict, transform=ImageTransformio(), phase=\"train\")\n",
    "val_dataset = BrainDataset(data_dict=val_datadict, transform=ImageTransformio(), phase=\"val\")\n",
    "\n",
    "print(\"size of the training dataset = \", len(train_dataset))\n",
    "print(\"size of the validation dataset = \", len(val_dataset))\n",
    "print(f\"training image shape = {train_dataset(0)[0].shape}, training label = {train_dataset(0)[1]}\")\n",
    "print(f\"test image shape = {val_dataset(0)[0].shape},     test label = {val_dataset(0)[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4987534f-a790-4ebf-91be-2401c69e9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像可視化関数\n",
    "def show_slice(gazo):\n",
    "\n",
    "    def _voxel2slice(voxel: np.array, aspect: str, slice_idx: int) -> np.array:\n",
    "        if aspect == 'sagittal':\n",
    "            slice_img = np.flip(voxel.transpose((0, 2, 1))[slice_idx], 0)\n",
    "        elif aspect == 'coronal':\n",
    "            slice_img = np.flip(voxel.transpose((1, 2, 0))[slice_idx], 0)\n",
    "        elif aspect == 'transverse':\n",
    "            slice_img = np.flip(voxel.transpose((2, 1, 0))[slice_idx], 0)\n",
    "        return slice_img\n",
    "\n",
    "    fig = plt.figure(figsize=(9,3))\n",
    "    trans = fig.add_subplot(1, 3, 1)\n",
    "    trans.set_title(\"transverse\", fontsize=12)\n",
    "    trans.imshow(_voxel2slice(gazo, 'transverse', 50), cmap='gray')\n",
    "    coronal = fig.add_subplot(1, 3, 2)\n",
    "    coronal.set_title(\"coronal\", fontsize=12)\n",
    "    coronal.imshow(_voxel2slice(gazo, 'coronal', 50), cmap='gray')\n",
    "    sagittal = fig.add_subplot(1, 3, 3)\n",
    "    sagittal.set_title(\"sagittal\", fontsize=12)\n",
    "    sagittal.imshow(_voxel2slice(gazo, 'sagittal', 50), cmap='gray')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "idx = 20\n",
    "img1, label1 = train_dataset(idx)\n",
    "img2, label2 = train_dataset(idx+1)\n",
    "\n",
    "print(\"mean=\", img1.mean())\n",
    "print(f\"max={img1.max()} min={img1.min()}\")\n",
    "print(label1)\n",
    "\n",
    "show_slice(img1.numpy().reshape(80, 96, 80))\n",
    "show_slice(img2.numpy().reshape(80, 96, 80))\n",
    "\n",
    "#imge = np.clip(image, 0, None)\n",
    "# print(img1.numpy().reshape(80, 80, 80).mean())\n",
    "# plt.imshow(np.flip(img1.numpy().reshape(80, 80, 80).transpose(2,0,1)[50],0), cmap=\"gray\")\n",
    "# plt.imshow(np.flip(img2.numpy().reshape(80, 80, 80).transpose(2,0,1)[50],0), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ff28a-9e4e-4d34-9d43-8bdeba7e4b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像１枚あたりの輝度値ヒストグラム\n",
    "idx = 20\n",
    "image, label = train_dataset(idx)\n",
    "print(\"mean=\", image.mean())\n",
    "print(f\"max={image.max()} min={image.min()}\")\n",
    "print(label)\n",
    "#imge = np.clip(image, 0, None)\n",
    "show_img = image.numpy().reshape(80*96*80)\n",
    "plt.hist(show_img[show_img > 0.01], bins=255)\n",
    "#plt.title(\"Accuracy\")\n",
    "#plt.xlabel(\"Epoch\")\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15f3720-ef18-4f42-89f7-64e70b331266",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list = []\n",
    "max = 0.01\n",
    "for image, label in train_dataset:\n",
    "    if max < image.max():\n",
    "        max = image.max()\n",
    "    image_reshape = image.numpy().reshape(80*96*80)\n",
    "    image_list.append(image_reshape)\n",
    "\n",
    "for image, label in val_dataset:\n",
    "    if max < image.max():\n",
    "        max = image.max()\n",
    "    image_reshape = image.numpy().reshape(80*96*80)\n",
    "    image_list.append(image_reshape)\n",
    "print(len(image_list))\n",
    "\n",
    "imagelist = np.concatenate(image_list)\n",
    "plt.title(\"Histogram of intensity rescale=(0, 1), in_min_max=(1, 255)\")\n",
    "plt.xlabel(\"Intensity\")\n",
    "plt.ylabel(\"Number\")\n",
    "plt.hist(imagelist[imagelist > 0.01], bins=255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa765b1-c594-40a2-a3d9-c72b4a8515f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c96c972-8cd9-45be-9e61-214d34ab5a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 画像の定量評価\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.metrics import mean_squared_error\n",
    "\n",
    "idx = 20\n",
    "img1, label1 = train_dataset(idx)\n",
    "img2, label2 = train_dataset(idx+1)\n",
    "img1 = np.flip(img1.numpy().reshape(80, 96, 80).transpose(2,0,1)[50],0)\n",
    "img2 = np.flip(img2.numpy().reshape(80, 96, 80).transpose(2,0,1)[50],0)\n",
    "\n",
    "mse_none = mean_squared_error(img1, img2)\n",
    "ssim_none = ssim(img1, img2)\n",
    "\n",
    "print(ssim_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e6ea07-9c15-4132-947f-1c5822a75394",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, num_workers=os.cpu_count(), pin_memory=True, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, num_workers=os.cpu_count(), pin_memory=True, shuffle=False)\n",
    "\n",
    "# for inputs, labels in train_dataloader:\n",
    "#     print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8d4c95-55e5-49d7-9b5d-506533935e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = models.LuckyNet()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b15044a-b13b-4881-b2d0-5474e128cdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.init.kaiming_normal(net.conv1.weight)\n",
    "torch.nn.init.kaiming_normal(net.conv2.weight)\n",
    "torch.nn.init.kaiming_normal(net.conv3.weight)\n",
    "torch.nn.init.kaiming_normal(net.conv4.weight)\n",
    "torch.nn.init.kaiming_normal(net.fc1.weight)\n",
    "torch.nn.init.kaiming_normal(net.fc2.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53df86e8-592f-4d2b-b5f9-6226e686e616",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "#optimizer = optim.SGD(params=net.parameters(), lr=0.0005, momentum=0.9)\n",
    "optimizer = optim.Adam(params=net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86e229-4c4a-4228-b8a4-550855c81568",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(net, train_dataloader, val_dataloader, criterion, optimizer, num_epochs):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net.to(device)\n",
    "    print(\"Use divice = \", device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        loss_avg = 0.0\n",
    "        acc_avg = 0.0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs = inputs.to(device=device, dtype=torch.float)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            acc_avg += torch.mean((preds == labels).float()).item() / len(train_dataloader)\n",
    "            loss_avg += loss.item() / len(train_dataloader)\n",
    "        train_losses.append(loss_avg)\n",
    "        train_accs.append(acc_avg)\n",
    "\n",
    "        # evaluate\n",
    "        loss_avg = 0.0 \n",
    "        acc_avg = 0.0\n",
    "        net.eval()\n",
    "        for inputs, labels in val_dataloader:\n",
    "            inputs = inputs.to(device=device, dtype=torch.float)\n",
    "            labels = labels.to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = net(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            acc_avg += torch.mean((preds == labels).float()).item() / len(val_dataloader)\n",
    "            loss_avg += loss.item() / len(val_dataloader)\n",
    "\n",
    "        test_losses.append(loss_avg)\n",
    "        test_accs.append(acc_avg)\n",
    "        print(f\"EPOCH {epoch+1}  || train loss : {train_losses[epoch]:.4f}, test loss : {test_losses[epoch]:.4f} \\\n",
    "            || train acc : {train_accs[epoch]:.4f} || test acc : {test_accs[epoch]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3cf005b-17cb-43bf-af5b-de89efafef33",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accs = []\n",
    "test_accs = []\n",
    "\n",
    "train_model(net, train_dataloader, val_dataloader, criterion, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f902da-b340-4750-9eb3-7c444b16bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_epochs), train_losses, label=\"train loss\")\n",
    "plt.plot(range(num_epochs), test_losses, label=\"test loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff913daa-399f-4546-99de-db61c084601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(num_epochs), train_accs, label=\"train acc\")\n",
    "plt.plot(range(num_epochs), test_accs, label=\"test acc\")\n",
    "plt.title(\"Accs\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accs\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2748785b-a3ac-4e33-ac2c-6bff5305a0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data_set[10][\"voxel\"].min(), data_set[10][\"voxel\"].max())\n",
    "#print(train_dataset(20)[0].min(), train_dataset(20)[0].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc9088c-6c94-4692-bc61-2a22d2b0784f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d73827-4cdd-449a-9452-9d2f56f29982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be67327-fd90-4e46-b487-c4a660ec8e7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e6c1b8-5fb4-4f9a-a8e6-1f9efd61898d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d0ab4-3488-4e0e-9cbb-5c289dd4b68c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
